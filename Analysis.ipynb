{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Notebook for the Paper \"Data-driven exploration and continuum modeling of dislocation networks\"\n",
    "\n",
    "By running this notebook, you should be able to reproduce all results and plots from Section 2 of the paper \"Data-driven exploration and continuum modeling of dislocation networks\".\n",
    "(Provided you have the data and you have adapted the hard-coded path to the CSV file).\n",
    "The overall goal is to predict reaction densities (*glissile*, *lomer*, *hirth*) based on dislocation densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "from matplotlib import cm # color mapping\n",
    "import numpy as np # numeric arrays\n",
    "import pandas as pd # data handling\n",
    "import re # regular expressions\n",
    "import scipy as sp # descriptive stats\n",
    "import seaborn as sns # grouped boxplots\n",
    "from sklearn import linear_model, preprocessing # ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Apart from column type conversion and the removal of an id column, there is no other pre-processing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/delta_sampled_merged_last_voxel_data_size2400_order2_speedUp2.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] # exclude unnamed columns\n",
    "df = df.apply(lambda x: pd.to_numeric(x, errors = 'raise')) # convert column types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute (exploration/prediction) targets\n",
    "\n",
    "We are interested in reaction densities for three reaction types.\n",
    "The reaction densities are summed over the 12 slip systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeatures = ['rho_glissile', 'rho_lomer', 'rho_coll']\n",
    "for targetFeature in targetFeatures:\n",
    "    df[targetFeature] = (df[targetFeature + '_1'])\n",
    "    for gs in range(2,13): # sum over slip systems\n",
    "        df[targetFeature] = df[targetFeature] + (df[targetFeature + '_' + str(gs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and plot data (Section 2.1 and 2.2)\n",
    "\n",
    "Before making predictions, we explore the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General dataset characteristics (Section 2.1)\n",
    "\n",
    "We begin by making some general statements about the size of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overall dataset size:', df.shape)\n",
    "for targetFeature in targetFeatures:\n",
    "    print('Actual number of data objects for ' + targetFeature + ':', sum(df[targetFeature] != 0))\n",
    "print('Voxel layout: ' + str(len(df.pos_x.unique())) + '*' + str(len(df.pos_y.unique())) + '*' + str(len(df.pos_z.unique())))\n",
    "print(str(len(df.time.unique())) + ' time steps: ' + ', '.join([str(x) for x in sorted(df.time.unique())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms of target features\n",
    "\n",
    "We plot histograms combined with Gaussian kernel density estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetFeature in targetFeatures:\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2)\n",
    "    fig.set_size_inches(w = 15, h = 3)\n",
    "    sns.distplot(df[targetFeature], ax = ax[0])\n",
    "    sns.distplot(df[targetFeature], ax = ax[1])\n",
    "    ax[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target features over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 3)\n",
    "fig.set_size_inches(w = 15, h = 3)\n",
    "for i in range(len(targetFeatures)):\n",
    "    sns.regplot(x = 'time', y = targetFeatures[i], data = df, ax = ax[i])\n",
    "plt.tight_layout() # prevents overlap of subfigures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target features over space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetFeature in targetFeatures:\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 3)\n",
    "    fig.set_size_inches(w = 15, h = 3)\n",
    "    sns.boxplot(x = 'pos_x', y = targetFeature, data = df, ax = ax[0]) # can also use scatterplot\n",
    "    sns.boxplot(x = 'pos_y', y = targetFeature, data = df, ax = ax[1])\n",
    "    sns.boxplot(x = 'pos_z', y = targetFeature, data = df, ax = ax[2])\n",
    "    plt.tight_layout() # prevents overlap of subfigures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dislocation density vs reaction density (Section 2.2, Figure 2 a/b/c)\n",
    "\n",
    "We provide some insights into the ground truth by plotting reaction density vs. dislocation density.\n",
    "This also motivates predictions with a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "a = 0.4040496e-9\n",
    "volume = 5e-6*5e-6*5e-6\n",
    "plotFeatures = ['rho_glissile', 'rho_lomer', 'rho_coll']\n",
    "yLabels = [r'Glissile reaction density $\\rho_\\mathrm{gliss}~[$m$^{-2}]$',\\\n",
    "           r'Lomer reaction density $\\rho_\\mathrm{lomer}~[$m$^{-2}]$',\\\n",
    "           r'Collinear reaction density $\\rho_\\mathrm{coll}~[$m$^{-2}]$']\n",
    "for i in range(len(plotFeatures)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim([1e11, 1e13])\n",
    "    ax.set_ylim([1e7,1e11])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')  \n",
    "    plotData = df[df[plotFeatures[i]] != 0]  \n",
    "    plt.scatter(plotData['rho_tot'] * a / volume, plotData[plotFeatures[i]] * a / volume,\\\n",
    "                c = plotData['n_loops'], cmap = cm.viridis, marker = 'o', vmin = 0, vmax = 600)\n",
    "    cb = plt.colorbar(label = r'Number of dislocations $[-]$')\n",
    "    plt.grid(linestyle = ':')\n",
    "    plt.xlabel(r'Total dislocation density $\\rho_\\mathrm{tot}~[$m$^{-2}]$')\n",
    "    plt.ylabel(yLabels[i])\n",
    "    plt.savefig('plots/' + plotFeatures[i].replace('rho_', '') + '_ground_truth_loglog_numberloops.pdf',\n",
    "                bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and predict data (Section 2.3)\n",
    "\n",
    "Now we want to desscribe the relationship between dislocation density and reaction density with prediction models.\n",
    "We will try out different feature sets, corresponding to the equations in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define reaction pairs\n",
    "\n",
    "These pairs of slip systems are relevant for reactions, based on domain knowledge.\n",
    "When we compute interaction features later, we will only consider these pre-defined pairs instead of all combinations of slip systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactionPairs = {\n",
    "    'rho_coll': [[1,12], [2,6], [3,9], [4,10], [5,8], [7,11]],\n",
    "    'rho_lomer': [[1,4], [1,7], [2,8], [2,10], [3,5], [3,11], [4,7], [5,11], [6,9], [6,12], [8,10], [9,12]],\n",
    "    'rho_glissile': [[1,6], [1,9], [1,10], [1,11], [2,4], [2,5], [2,9], [2,12], [3,6], [3,7],\\\n",
    "                     [3,8], [3,12], [4,8], [4,11], [4,12], [5,7], [5,9], [5,10], [6,8], [6,10],\\\n",
    "                     [7,10], [7,12], [8,11], [9,11]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We compute three types of features, separately for each reaction type.\n",
    "All features are based on the pre-defined reaction types and combine dislocation densities from different slip systems:\n",
    "\n",
    "- single interaction terms, i.e., two terms for each reaction pair (`system1 * sqrt(system2)` and `sqrt(system1) * system2`)\n",
    "- biviariate interaction terms, i.e., one term for each reaction pair (sum of the two *single* terms)\n",
    "- overall interaction term, i.e., sum over all *single* interaction terms\n",
    "\n",
    "For another analysis, we also keep the raw dislocation densities in the dataset.\n",
    "Furthermore, we retain the space and time attributes which will come handy when splitting the data in cross-validation.\n",
    "All irrelevant columns are discarded.\n",
    "We store thre pre-defined lists of features and will re-use them during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densityFeatures = [x for x in list(df) if re.match( '^rho_[0-9]+$', x)] # raw densities; same for all reaction types\n",
    "reactFeaturesSingle = dict() # specific to reaction type (depends on reaction pairs)\n",
    "reactFeaturesBi = dict() # specific to reaction type (depends on reaction pairs)\n",
    "reactFeaturesAll = ['reactAll'] # same name for all reaction types (though computation depends on reaction pairs)\n",
    "predictionData = dict() # specific to reaction type (depends on features included)\n",
    "\n",
    "for targetFeature in targetFeatures:\n",
    "    # Reduce to dislocation densities, split-relevant features, and target\n",
    "    curPredictionData = df[densityFeatures + ['pos_x', 'pos_y', 'pos_z', 'time', targetFeature]]\n",
    "    \n",
    "    # Remove voxels without density\n",
    "    curPredictionData = curPredictionData[curPredictionData[targetFeature] != 0]\n",
    "    \n",
    "    # Engineer interaction features\n",
    "    curPredictionData['reactAll'] = np.zeros(curPredictionData.shape[0])\n",
    "    for pair in reactionPairs[targetFeature]:\n",
    "        name1 = 'reactSingle_' + str(pair[0]) + '_sqrt' + str(pair[1])\n",
    "        name2 = 'reactSingle_sqrt' + str(pair[0]) + \"_\" + str(pair[1])\n",
    "        value1 = curPredictionData['rho_' + str(pair[0])] *\\\n",
    "            curPredictionData['rho_' + str(pair[1])].apply(lambda x: math.sqrt(x))\n",
    "        value2 =  curPredictionData['rho_' + str(pair[1])] *\\\n",
    "            curPredictionData['rho_' + str(pair[0])].apply(lambda x: math.sqrt(x))\n",
    "        curPredictionData[name1] = value1\n",
    "        curPredictionData[name2] = value2\n",
    "        curPredictionData['reactBi_' + str(pair[0]) + '_' + str(pair[1])] = value1 + value2\n",
    "        curPredictionData['reactAll'] = curPredictionData['reactAll'] + value1 + value2\n",
    "    reactFeaturesSingle[targetFeature] = [x for x in list(curPredictionData) if re.match( '^reactSingle', x)]\n",
    "    reactFeaturesBi[targetFeature] = [x for x in list(curPredictionData) if re.match( '^reactBi', x)]\n",
    "    predictionData[targetFeature] = curPredictionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Also add single interaction terms for interactions not in pre-defined interaction pairs\n",
    "# reactFeaturesNot = dict() # specific to reaction type (depends on reaction pairs)\n",
    "# for targetFeature in targetFeatures:\n",
    "#     for i in range(1, 12):\n",
    "#         for j in range(i+1, 13):\n",
    "#             if [i, j] not in reactionPairs[targetFeature]:\n",
    "#                 name1 = 'reactNot_' + str(i) + '_sqrt' + str(j)\n",
    "#                 name2 = 'reactNot_sqrt' + str(i) + \"_\" + str(j)\n",
    "#                 value1 = predictionData[targetFeature]['rho_' + str(i)] *\\\n",
    "#                     predictionData[targetFeature]['rho_' + str(j)].apply(lambda x: math.sqrt(x))\n",
    "#                 value2 =  predictionData[targetFeature]['rho_' + str(j)] *\\\n",
    "#                     predictionData[targetFeature]['rho_' + str(i)].apply(lambda x: math.sqrt(x))\n",
    "#                 predictionData[targetFeature][name1] = value1\n",
    "#                 predictionData[targetFeature][name2] = value2\n",
    "#     reactFeaturesNot[targetFeature] = [x for x in list(curPredictionData) if re.match( '^reactNot', x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation of different feature types with summed reaction density (Figure 4)\n",
    "\n",
    "Correlate the different feature sets with the standard target, which is the reaction density summed over all slip systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "plotFeatures = ['rho_glissile', 'rho_lomer', 'rho_coll']\n",
    "plotTitles = ['Glissile reaction', 'Lomer reaction', 'Collinear reaction']\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, sharey = True)\n",
    "fig.set_size_inches(w = 15, h = 5)\n",
    "for i in range(len(plotFeatures)):\n",
    "    plotFeature = plotFeatures[i]\n",
    "    inputData = predictionData[plotFeature]\n",
    "    inputData = inputData.drop(columns = ['pos_x', 'pos_y', 'pos_z', 'time'])\n",
    "    correlations = [np.corrcoef(inputData[feature], inputData[plotFeature])[0,1] for feature in list(inputData)]\n",
    "    corrData = pd.DataFrame({'Feature': list(inputData), 'Correlation': correlations, 'Category': ''})\n",
    "    corrData.loc[corrData.Feature.isin(densityFeatures), 'Category'] = 'Dislocation densities'\n",
    "    corrData.loc[corrData.Feature.isin(reactFeaturesSingle[plotFeature]), 'Category'] = 'Eq. (1)'\n",
    "    corrData.loc[corrData.Feature.isin(reactFeaturesBi[plotFeature]), 'Category'] = \\\n",
    "        r'Eq. (1) with $\\forall\\xi~\\forall\\zeta~\\beta_1^{\\xi\\zeta} = \\beta_2^{\\xi\\zeta}$'\n",
    "    corrData.loc[corrData.Feature.isin(reactFeaturesAll), 'Category'] = 'Eq. (2)'\n",
    "#     corrData.loc[corrData.Feature.isin(reactFeaturesNot[plotFeature]), 'Category'] = 'ReactNot'\n",
    "#     corrData.loc[corrData.Feature == plotFeature, 'Category'] = 'Target'\n",
    "    corrData = corrData[corrData.Feature != plotFeature]\n",
    "    sns.boxplot(y = 'Category', x = 'Correlation', data = corrData, ax = ax[i])\n",
    "    ax[i].set_title(plotTitles[i])\n",
    "    ax[i].set_ylabel('Feature set')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/feature_correlation.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation of different feature types with reaction density on slip systems\n",
    "\n",
    "Correlate the different feature sets with the individual reaction densities on the different slip systems.\n",
    "The box plot then summarizes this over all slip systems and all features of a certain type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, sharey = True)\n",
    "fig.set_size_inches(w = 15, h = 5)\n",
    "for i in range(len(targetFeatures)):\n",
    "    targetFeature = targetFeatures[i]\n",
    "    inputData = predictionData[targetFeature]\n",
    "    inputData = inputData.drop(columns = ['pos_x', 'pos_y', 'pos_z', 'time'])\n",
    "    correlations = [np.corrcoef(inputData[feature],\n",
    "                                df.loc[df[targetFeature] != 0, targetFeature + '_' + str(targetNumber)])[0,1]\n",
    "                    for feature in list(inputData) for targetNumber in range(1,13)]\n",
    "    corrData = pd.DataFrame({'Feature': np.repeat(list(inputData), 12), 'Correlation': correlations, 'Category': ''})\n",
    "    corrData.loc[corrData.Feature.isin(densityFeatures), 'Category'] = 'RawDensity'\n",
    "    corrData.loc[corrData.Feature.isin(reactFeaturesSingle[targetFeature]), 'Category'] = 'ReactSingle'\n",
    "    corrData.loc[corrData.Feature.isin(reactFeaturesBi[targetFeature]), 'Category'] = 'ReactBi'\n",
    "    corrData.loc[corrData.Feature.isin(reactFeaturesAll), 'Category'] = 'ReactAll'\n",
    "#     corrData.loc[corrData.Feature.isin(reactFeaturesNot[targetFeature]), 'Category'] = 'ReactNot'\n",
    "    corrData.loc[corrData.Feature == targetFeature, 'Category'] = 'Target'\n",
    "    sns.boxplot(y = 'Category', x = 'Correlation', data = corrData, ax = ax[i])\n",
    "    ax[i].set_title(targetFeature)\n",
    "    ax[i].set_ylabel('Feature category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction pipeline\n",
    "\n",
    "Our prediction pipeline is rather short.\n",
    "It consists of:\n",
    "\n",
    "- (temporal) train-test split\n",
    "- dropping highly correlated features\n",
    "- min-max scaling\n",
    "- (optional) filter feature selection based on Pearson correlation\n",
    "- training of a linear regression model\n",
    "- prediction\n",
    "- evaluation\n",
    "- (optional) predicted-vs-ground-truth plot and various diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds highly correlated columns in the train data and removes them from train as well as test data.\n",
    "# https://stackoverflow.com/a/44674459\n",
    "def dropCorrelatedFeatures(X_train, X_test = None):\n",
    "    corr_cols = []\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        if (corr_matrix.columns[i] not in corr_cols):\n",
    "            for j in range(i):\n",
    "                if (corr_matrix.iloc[i, j] >= 0.95) and (corr_matrix.columns[j] not in corr_cols):\n",
    "                    corr_cols.append(corr_matrix.columns[i])\n",
    "    X_train = X_train.drop(columns = corr_cols)\n",
    "    if X_test is not None:\n",
    "        X_test = X_test.drop(columns = corr_cols)\n",
    "    return X_train, X_test\n",
    "\n",
    "# Trains a scaling approach on the train data and returns the scaled train data and test data.\n",
    "def scaleData(X_train, X_test = None):\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "    if X_test is not None:\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "    return X_train, X_test\n",
    "\n",
    "# Creates a plot with predicted vs ground truth values and saves it to the hard-drive.\n",
    "def plotPredictedVsGroundTruth(predicted, groundTruth, targetName):\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(groundTruth, predicted, 'ro', markersize = 5) # scatter plot with red circles\n",
    "    mxY=max(max(groundTruth), max(predicted))\n",
    "    mnY=min(min(groundTruth), min(predicted))\n",
    "    plt.plot([mnY,mxY], [mnY,mxY], 'k') # k means color = black\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(linestyle=':')\n",
    "    plt.savefig('plots/' + targetName.replace('rho_', '') + '_predicted_vs_ground_truth_scaling.pdf')\n",
    "\n",
    "# Creates various diagnostic plots.\n",
    "def plotDiagnostics(predicted, groundTruth):\n",
    "    residuals = predicted - groundTruth\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 4)\n",
    "    fig.set_size_inches(w = 15, h = 4)\n",
    "    sns.distplot(a = residuals, ax = ax[0], axlabel = 'Residuals')\n",
    "    ax[0].set_title('Residuals distribution')\n",
    "    sp.stats.probplot(x = residuals, dist = 'norm', plot = ax[1])\n",
    "    ax[1].set_title('Residuals Q-Q')\n",
    "    sns.scatterplot(x = predicted, y = residuals, ax = ax[2])\n",
    "    ax[2].set_xlabel('Predicted')\n",
    "    ax[2].set_ylabel('Residuals')\n",
    "    ax[2].set_title('Residuals vs. predicted')\n",
    "    sns.scatterplot(x = groundTruth, y = residuals, ax = ax[3])\n",
    "    ax[3].set_xlabel('Ground truth')\n",
    "    ax[3].set_ylabel('Residuals')\n",
    "    ax[3].set_title('Residuals vs. ground truth')\n",
    "    plt.tight_layout() # prevents overlap of subfigures\n",
    "\n",
    "# Runs the full prediction pipeline and returns the trained regression model,\n",
    "# training set scores and test set scores.\n",
    "# Predicted-vs-ground-truth plots and filter feature selection are optional.\n",
    "# If you want to use the latter, you can specify the number of features to be\n",
    "# selected (absolute or fraction).\n",
    "def evaluateWithLM(dataset, features, target, plot = False, filterFS = 0):\n",
    "\n",
    "    # Train-test split\n",
    "    X_train = dataset[features][dataset.time <= 6000]\n",
    "    X_test = dataset[features][dataset.time > 6000]\n",
    "    y_train = dataset[target][dataset.time <= 6000]\n",
    "    y_test = dataset[target][dataset.time > 6000]\n",
    "\n",
    "    # Drop highly correlated features\n",
    "    X_train, X_test = dropCorrelatedFeatures(X_train, X_test)\n",
    "\n",
    "    # Scaling\n",
    "    X_train, X_test = scaleData(X_train, X_test)\n",
    "\n",
    "    # Filter feature selection (optional)\n",
    "    if filterFS > 0:\n",
    "        if filterFS < 1: # relative number of features\n",
    "            filterFS = round(filterFS * len(features)) # turn absolute\n",
    "        if filterFS < X_train.shape[1]: # else feature selection does not make sense\n",
    "            corrCoeffs = [sp.stats.pearsonr(X_train[x], y_train)[0] for x in list(X_train)]\n",
    "            topFeatureIndices = np.argsort([-abs(x) for x in corrCoeffs])[0:filterFS] # sort abs correlation decreasingly\n",
    "            topFeatures = [list(X_train)[x] for x in topFeatureIndices]\n",
    "            X_train = X_train[topFeatures]\n",
    "            X_test = X_test[topFeatures]\n",
    "\n",
    "    # Training\n",
    "    lm = linear_model.LinearRegression()\n",
    "    reg = lm.fit(X_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = reg.predict(X_train)\n",
    "    y_test_pred = reg.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print('Train R^2:', round(reg.score(X_train, y_train), 3))\n",
    "    print('Test R^2:', round(reg.score(X_test, y_test), 3))\n",
    "    print('Summary of coefficients:', sp.stats.describe(reg.coef_))\n",
    "    \n",
    "    # Plotting (optional)\n",
    "    if plot:\n",
    "        plotPredictedVsGroundTruth(predicted = y_test_pred, groundTruth = y_test, targetName = target)\n",
    "        plotDiagnostics(predicted = y_test_pred, groundTruth = y_test)\n",
    "\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model (two interaction terms per reaction pair, Figure 3 a/b/c)\n",
    "\n",
    "We evaluate the quality of a linear regression model for the reaction density.\n",
    "Each interaction term gets its own coefficient in the model.\n",
    "We also create several diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyzes the difference between two regression coefficients belonging to same reaction pair.\n",
    "# Only works if there are two features for each reaction pair.\n",
    "def evaluateCoefficientDiff(regModel, features, plot = True):\n",
    "    # Assume each two (odd, even) elements in \"features\" belong to the same reaction pair\n",
    "    featureNamesWithoutSqrt = [x.replace('sqrt', '') for x in features]\n",
    "    assert featureNamesWithoutSqrt[::2] == featureNamesWithoutSqrt[1::2] # odd == even?\n",
    "    assert len(regModel.coef_) == len(features)\n",
    "    coefficients_1_2sqrt = regModel.coef_[::2]\n",
    "    coefficients_sqrt1_2 = regModel.coef_[1::2]\n",
    "    coefficientDiff = coefficients_1_2sqrt - coefficients_sqrt1_2\n",
    "    relCoefficientDiff = abs(coefficientDiff / coefficients_1_2sqrt * 100)\n",
    "    print('Deviation in % of 2nd to 1st coefficient within reaction pair:', sp.stats.describe(relCoefficientDiff))\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(nrows = 1, ncols = 2)\n",
    "        fig.set_size_inches(w = 15, h = 3)\n",
    "        ax[0].boxplot(relCoefficientDiff, showfliers = False) # excludes outliers\n",
    "        ax[0].set_xlabel('Deviation in % of 2nd to 1st coefficient')\n",
    "        ax[1].hist(relCoefficientDiff, range = (0,200), bins = 20)\n",
    "        ax[1].xaxis.set_major_locator(plt.MultipleLocator(20)) # ticks\n",
    "        ax[1].set_xlabel('Deviation in % of 2nd to 1st coefficient')\n",
    "\n",
    "for targetFeature in targetFeatures:\n",
    "    print('----- ' + targetFeature + ' -----')\n",
    "    regModel = evaluateWithLM(dataset = predictionData[targetFeature],\\\n",
    "        features = reactFeaturesSingle[targetFeature], target = targetFeature, plot = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter feature selection\n",
    "\n",
    "First, we correlate the Pearson correlation of each (interaction) feature with the prediction target.\n",
    "Next, we summarize and plot this correlation.\n",
    "Finally, we train a regression model using just a fraction of the features, selecting them by absolute correlation.\n",
    "Note that the top features used there might differ from the top features found in the explorative analysis presented first, because the filter feature selection for prediction is only conducted on the training data (as it should be) and not the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for targetFeature in targetFeatures:\n",
    "    print('----- ' + targetFeature + ' -----')\n",
    "    corrCoeffs = [sp.stats.pearsonr(predictionData[targetFeature][x],\\\n",
    "        predictionData[targetFeature][targetFeature])[0] for x in reactFeaturesSingle[targetFeature]]\n",
    "    print('\\nSummary of correlation of interaction features with target:', sp.stats.describe(corrCoeffs))\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2)\n",
    "    fig.set_size_inches(w = 15, h = 3)\n",
    "    ax[0].boxplot(corrCoeffs)\n",
    "    ax[0].set_xlabel('Correlation of features with target')\n",
    "    ax[1].hist(corrCoeffs, range = (0,1), bins = 20)\n",
    "    ax[1].xaxis.set_major_locator(plt.MultipleLocator(0.1)) # ticks\n",
    "    ax[1].set_xlabel('Correlation of features with target')\n",
    "    plt.show()\n",
    "    topFeatureIndices = np.argsort([-abs(x) for x in corrCoeffs])[0:5] # sort absolute correlation decreasingly\n",
    "    topFeatures = [reactFeaturesSingle[targetFeature][x] for x in topFeatureIndices]\n",
    "    print('Top 5 highest-correlated features:', topFeatures)\n",
    "    print('Model with 1/3 highest-correlated features:')\n",
    "    evaluateWithLM(dataset = predictionData[targetFeature], features = reactFeaturesSingle[targetFeature],\\\n",
    "                   target = targetFeature, plot = False, filterFS = 1/3)\n",
    "    print('Model with 1/6 highest-correlated features:')\n",
    "    evaluateWithLM(dataset = predictionData[targetFeature], features = reactFeaturesSingle[targetFeature],\\\n",
    "                   target = targetFeature, plot = False, filterFS = 1/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate interaction terms (one interaction term per reaction pair)\n",
    "\n",
    "This model merges the two coefficients of each reaction pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetFeature in targetFeatures:\n",
    "    print('----- ' + targetFeature + ' -----')\n",
    "    evaluateWithLM(dataset = predictionData[targetFeature], features = reactFeaturesBi[targetFeature],\\\n",
    "                   target = targetFeature, plot = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One (overall) interaction term\n",
    "\n",
    "This model only has one coefficient, which weights the sum over all reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetFeature in targetFeatures:\n",
    "    print('----- ' + targetFeature + ' -----')\n",
    "    evaluateWithLM(dataset = predictionData[targetFeature], features = reactFeaturesAll,\\\n",
    "                   target = targetFeature, plot = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No interaction terms\n",
    "\n",
    "This model only uses the dislocation densities from the 12 slip systems.\n",
    "No interaction terms between slip systems are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetFeature in targetFeatures:\n",
    "    print('----- ' + targetFeature + ' -----')\n",
    "    evaluateWithLM(dataset = predictionData[targetFeature], features = densityFeatures,\\\n",
    "                   target = targetFeature, plot = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dislocation_networks_kernel",
   "language": "python",
   "name": "dislocation_networks_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
